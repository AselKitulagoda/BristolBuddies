## Product evaluation

#### Questionnaire evaluation

We started our evaluation process by reviewing the questionnaire we created to meaningfully match the users. We interviewed study abroad students and buddies to learn more about what they would find important in their match. We interviewed a total of 3 buddies and 3 students and we made notes using a shared document.

We gave them the first iteration of our questionnaire, a stripped down version of the Bristol Student Union's personality questionnaire, and asked them to rank all categories in order of importance when considering their match. This helped us remove information they thought was irrelevant, such as gender or age, and focus on the four recurring criteria for a good match : course, nationality, personality and interests. However, every student had a different point-of-view on what a good match meant to them. We thus decided to let the user control the factors they would be matched on, through a preference hierarchy.


#### Application evaluation

We decided to evaluate our application through a qualitative approach, by producing a questionnaire to find out if our application fulfills its purpose and identify possible areas of improvement. We received a total of 16 responses to our questionnaire which were mainly distributed among university students who form the intended target audience for the application. We also focused questions on the usability of the application, overall design and matching algorithm which forms the basis of our system. 

The evaluation showed us that while around 40% of users would be willing to try an integrated third-party messaging app to communicate with their buddies, 90% of them would rather use Messenger, WhatsApp or Gmail. They do not see the need to have another messaging service with so many already present in the market. This, coupled with the time constraints we faced, led to us not fully implementing the messaging feature, and decided instead to display the interests and personality traits the student and buddy have in common. This makes it easier for buddies, and act as an *"icebreaker"* for when contact begins.

The analysis revealed that more than 80% of users were satisfied with the core function of our app, the matching algorithm. One of the students was not matched with anyone, we later figured out this was because we did not create enough mock buddies. The other students complained they were unsure about why they were matched with their buddies. That reinforced our decision to display the similarities between them and their match.
We also noticed students would enter their nationality in different ways, for example french/France, which meant our matching algorithm didn't work properly. This was fixed by creating drop-down lists for both the faculty and the country of origin.

Finally, every student found the app intuitive in terms of navigation, and the events page simple and easy to follow. One recurring complaint was the design and colors of the app, which the users found unattractive. For example, the colors we used in the event page, red and green, did not work well with each other. We fixed that by changing it to red and white, however we did not spend as much time as we would have liked on the design, due to the time constraint.